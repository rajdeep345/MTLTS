{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "name": "MTL Code Setup",
      "provenance": [],
      "collapsed_sections": []
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "accelerator": "GPU"
  },
  "cells": [
    {
      "cell_type": "code",
      "metadata": {
        "id": "vwIiTF15f6bY",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "08fd6640-43d7-40b5-9fc4-7c8d78da23a2"
      },
      "source": [
        "!pip install transformers==3.0.0 --quiet\n",
        "!pip3 install fastBPE --quiet"
      ],
      "execution_count": 8,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "\u001b[K     |████████████████████████████████| 757kB 28.7MB/s \n",
            "\u001b[K     |████████████████████████████████| 1.2MB 26.0MB/s \n",
            "\u001b[K     |████████████████████████████████| 3.0MB 46.7MB/s \n",
            "\u001b[K     |████████████████████████████████| 901kB 53.4MB/s \n",
            "\u001b[?25h  Building wheel for fastBPE (setup.py) ... \u001b[?25l\u001b[?25hdone\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "yxNACGoeg8E2",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "df90e3fb-796c-42ff-9d98-e1eeebcf4bc0"
      },
      "source": [
        "!pip install py-rouge --quiet\n",
        "!pip install textstat --quiet"
      ],
      "execution_count": 9,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "\u001b[K     |████████████████████████████████| 61kB 9.0MB/s \n",
            "\u001b[K     |████████████████████████████████| 102kB 9.6MB/s \n",
            "\u001b[K     |████████████████████████████████| 1.9MB 41.0MB/s \n",
            "\u001b[?25h"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "t-f8O5NQhUZY",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "812c20bd-2719-4697-e1f6-bef17670f2df"
      },
      "source": [
        "import nltk\n",
        "nltk.download('punkt')"
      ],
      "execution_count": 10,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "[nltk_data] Downloading package punkt to /root/nltk_data...\n",
            "[nltk_data]   Unzipping tokenizers/punkt.zip.\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "True"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 10
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "ErfvqjnVhihp",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "768a7881-5932-493e-c0a9-d211c701c031"
      },
      "source": [
        "!git clone https://github.com/pytorch/fairseq"
      ],
      "execution_count": 11,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Cloning into 'fairseq'...\n",
            "remote: Enumerating objects: 28229, done.\u001b[K\n",
            "remote: Counting objects:   2% (1/48)\u001b[K\rremote: Counting objects:   4% (2/48)\u001b[K\rremote: Counting objects:   6% (3/48)\u001b[K\rremote: Counting objects:   8% (4/48)\u001b[K\rremote: Counting objects:  10% (5/48)\u001b[K\rremote: Counting objects:  12% (6/48)\u001b[K\rremote: Counting objects:  14% (7/48)\u001b[K\rremote: Counting objects:  16% (8/48)\u001b[K\rremote: Counting objects:  18% (9/48)\u001b[K\rremote: Counting objects:  20% (10/48)\u001b[K\rremote: Counting objects:  22% (11/48)\u001b[K\rremote: Counting objects:  25% (12/48)\u001b[K\rremote: Counting objects:  27% (13/48)\u001b[K\rremote: Counting objects:  29% (14/48)\u001b[K\rremote: Counting objects:  31% (15/48)\u001b[K\rremote: Counting objects:  33% (16/48)\u001b[K\rremote: Counting objects:  35% (17/48)\u001b[K\rremote: Counting objects:  37% (18/48)\u001b[K\rremote: Counting objects:  39% (19/48)\u001b[K\rremote: Counting objects:  41% (20/48)\u001b[K\rremote: Counting objects:  43% (21/48)\u001b[K\rremote: Counting objects:  45% (22/48)\u001b[K\rremote: Counting objects:  47% (23/48)\u001b[K\rremote: Counting objects:  50% (24/48)\u001b[K\rremote: Counting objects:  52% (25/48)\u001b[K\rremote: Counting objects:  54% (26/48)\u001b[K\rremote: Counting objects:  56% (27/48)\u001b[K\rremote: Counting objects:  58% (28/48)\u001b[K\rremote: Counting objects:  60% (29/48)\u001b[K\rremote: Counting objects:  62% (30/48)\u001b[K\rremote: Counting objects:  64% (31/48)\u001b[K\rremote: Counting objects:  66% (32/48)\u001b[K\rremote: Counting objects:  68% (33/48)\u001b[K\rremote: Counting objects:  70% (34/48)\u001b[K\rremote: Counting objects:  72% (35/48)\u001b[K\rremote: Counting objects:  75% (36/48)\u001b[K\rremote: Counting objects:  77% (37/48)\u001b[K\rremote: Counting objects:  79% (38/48)\u001b[K\rremote: Counting objects:  81% (39/48)\u001b[K\rremote: Counting objects:  83% (40/48)\u001b[K\rremote: Counting objects:  85% (41/48)\u001b[K\rremote: Counting objects:  87% (42/48)\u001b[K\rremote: Counting objects:  89% (43/48)\u001b[K\rremote: Counting objects:  91% (44/48)\u001b[K\rremote: Counting objects:  93% (45/48)\u001b[K\rremote: Counting objects:  95% (46/48)\u001b[K\rremote: Counting objects:  97% (47/48)\u001b[K\rremote: Counting objects: 100% (48/48)\u001b[K\rremote: Counting objects: 100% (48/48), done.\u001b[K\n",
            "remote: Compressing objects: 100% (30/30), done.\u001b[K\n",
            "remote: Total 28229 (delta 22), reused 32 (delta 18), pack-reused 28181\u001b[K\n",
            "Receiving objects: 100% (28229/28229), 11.80 MiB | 28.84 MiB/s, done.\n",
            "Resolving deltas: 100% (21218/21218), done.\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "LkpFw2zPhqQ2",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "5a1fdf1b-c908-457e-e1bb-0be5cefa3652"
      },
      "source": [
        "!pip install --editable ./fairseq/"
      ],
      "execution_count": 12,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Obtaining file:///content/fairseq\n",
            "  Installing build dependencies ... \u001b[?25l\u001b[?25hdone\n",
            "  Getting requirements to build wheel ... \u001b[?25l\u001b[?25hdone\n",
            "  Installing backend dependencies ... \u001b[?25l\u001b[?25hdone\n",
            "    Preparing wheel metadata ... \u001b[?25l\u001b[?25hdone\n",
            "Requirement already satisfied: numpy; python_version >= \"3.7\" in /usr/local/lib/python3.7/dist-packages (from fairseq==1.0.0a0+fc391ff) (1.19.5)\n",
            "Requirement already satisfied: tqdm in /usr/local/lib/python3.7/dist-packages (from fairseq==1.0.0a0+fc391ff) (4.41.1)\n",
            "Requirement already satisfied: regex in /usr/local/lib/python3.7/dist-packages (from fairseq==1.0.0a0+fc391ff) (2019.12.20)\n",
            "Collecting hydra-core<1.1\n",
            "\u001b[?25l  Downloading https://files.pythonhosted.org/packages/52/e3/fbd70dd0d3ce4d1d75c22d56c0c9f895cfa7ed6587a9ffb821d6812d6a60/hydra_core-1.0.6-py3-none-any.whl (123kB)\n",
            "\u001b[K     |████████████████████████████████| 133kB 27.1MB/s \n",
            "\u001b[?25hRequirement already satisfied: torch in /usr/local/lib/python3.7/dist-packages (from fairseq==1.0.0a0+fc391ff) (1.8.1+cu101)\n",
            "Requirement already satisfied: cffi in /usr/local/lib/python3.7/dist-packages (from fairseq==1.0.0a0+fc391ff) (1.14.5)\n",
            "Collecting omegaconf<2.1\n",
            "  Downloading https://files.pythonhosted.org/packages/d0/eb/9d63ce09dd8aa85767c65668d5414958ea29648a0eec80a4a7d311ec2684/omegaconf-2.0.6-py3-none-any.whl\n",
            "Collecting sacrebleu>=1.4.12\n",
            "\u001b[?25l  Downloading https://files.pythonhosted.org/packages/7e/57/0c7ca4e31a126189dab99c19951910bd081dea5bbd25f24b77107750eae7/sacrebleu-1.5.1-py3-none-any.whl (54kB)\n",
            "\u001b[K     |████████████████████████████████| 61kB 8.3MB/s \n",
            "\u001b[?25hRequirement already satisfied: cython in /usr/local/lib/python3.7/dist-packages (from fairseq==1.0.0a0+fc391ff) (0.29.23)\n",
            "Requirement already satisfied: importlib-resources; python_version < \"3.9\" in /usr/local/lib/python3.7/dist-packages (from hydra-core<1.1->fairseq==1.0.0a0+fc391ff) (5.1.3)\n",
            "Collecting antlr4-python3-runtime==4.8\n",
            "\u001b[?25l  Downloading https://files.pythonhosted.org/packages/56/02/789a0bddf9c9b31b14c3e79ec22b9656185a803dc31c15f006f9855ece0d/antlr4-python3-runtime-4.8.tar.gz (112kB)\n",
            "\u001b[K     |████████████████████████████████| 112kB 42.0MB/s \n",
            "\u001b[?25hRequirement already satisfied: typing-extensions in /usr/local/lib/python3.7/dist-packages (from torch->fairseq==1.0.0a0+fc391ff) (3.7.4.3)\n",
            "Requirement already satisfied: pycparser in /usr/local/lib/python3.7/dist-packages (from cffi->fairseq==1.0.0a0+fc391ff) (2.20)\n",
            "Collecting PyYAML>=5.1.*\n",
            "\u001b[?25l  Downloading https://files.pythonhosted.org/packages/7a/a5/393c087efdc78091afa2af9f1378762f9821c9c1d7a22c5753fb5ac5f97a/PyYAML-5.4.1-cp37-cp37m-manylinux1_x86_64.whl (636kB)\n",
            "\u001b[K     |████████████████████████████████| 645kB 42.3MB/s \n",
            "\u001b[?25hCollecting portalocker==2.0.0\n",
            "  Downloading https://files.pythonhosted.org/packages/89/a6/3814b7107e0788040870e8825eebf214d72166adf656ba7d4bf14759a06a/portalocker-2.0.0-py2.py3-none-any.whl\n",
            "Requirement already satisfied: zipp>=0.4; python_version < \"3.8\" in /usr/local/lib/python3.7/dist-packages (from importlib-resources; python_version < \"3.9\"->hydra-core<1.1->fairseq==1.0.0a0+fc391ff) (3.4.1)\n",
            "Building wheels for collected packages: antlr4-python3-runtime\n",
            "  Building wheel for antlr4-python3-runtime (setup.py) ... \u001b[?25l\u001b[?25hdone\n",
            "  Created wheel for antlr4-python3-runtime: filename=antlr4_python3_runtime-4.8-cp37-none-any.whl size=141231 sha256=5a26ad240ce58d4163098205c6f9a6c3447c9ec164ca6804a455709315442872\n",
            "  Stored in directory: /root/.cache/pip/wheels/e3/e2/fa/b78480b448b8579ddf393bebd3f47ee23aa84c89b6a78285c8\n",
            "Successfully built antlr4-python3-runtime\n",
            "Installing collected packages: PyYAML, omegaconf, antlr4-python3-runtime, hydra-core, portalocker, sacrebleu, fairseq\n",
            "  Found existing installation: PyYAML 3.13\n",
            "    Uninstalling PyYAML-3.13:\n",
            "      Successfully uninstalled PyYAML-3.13\n",
            "  Running setup.py develop for fairseq\n",
            "Successfully installed PyYAML-5.4.1 antlr4-python3-runtime-4.8 fairseq hydra-core-1.0.6 omegaconf-2.0.6 portalocker-2.0.0 sacrebleu-1.5.1\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "54fOYpk2hzYm",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "ebd6cb8b-2d66-46d2-d14d-9fbb49a108bd"
      },
      "source": [
        "!wget https://public.vinai.io/BERTweet_base_transformers.tar.gz\n",
        "!tar -xzvf BERTweet_base_transformers.tar.gz"
      ],
      "execution_count": 13,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "--2021-06-07 15:29:33--  https://public.vinai.io/BERTweet_base_transformers.tar.gz\n",
            "Resolving public.vinai.io (public.vinai.io)... 13.225.209.16, 13.225.209.82, 13.225.209.84, ...\n",
            "Connecting to public.vinai.io (public.vinai.io)|13.225.209.16|:443... connected.\n",
            "HTTP request sent, awaiting response... 200 OK\n",
            "Length: 322076118 (307M) [application/x-tar]\n",
            "Saving to: ‘BERTweet_base_transformers.tar.gz’\n",
            "\n",
            "BERTweet_base_trans 100%[===================>] 307.16M  12.3MB/s    in 27s     \n",
            "\n",
            "2021-06-07 15:30:02 (11.3 MB/s) - ‘BERTweet_base_transformers.tar.gz’ saved [322076118/322076118]\n",
            "\n",
            "BERTweet_base_transformers/\n",
            "BERTweet_base_transformers/config.json\n",
            "BERTweet_base_transformers/bpe.codes\n",
            "BERTweet_base_transformers/model.bin\n",
            "BERTweet_base_transformers/dict.txt\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "vQGIUXp1AT5Z",
        "outputId": "dc6eae2d-a79f-4ecc-fcbe-6136ace26673"
      },
      "source": [
        "# clone the repo\n",
        "!git clone \"Repo URL\""
      ],
      "execution_count": 7,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Cloning into 'MTLVS'...\n",
            "remote: Enumerating objects: 323, done.\u001b[K\n",
            "remote: Counting objects: 100% (98/98), done.\u001b[K\n",
            "remote: Compressing objects: 100% (86/86), done.\u001b[K\n",
            "remote: Total 323 (delta 27), reused 46 (delta 9), pack-reused 225\u001b[K\n",
            "Receiving objects: 100% (323/323), 50.05 MiB | 19.56 MiB/s, done.\n",
            "Resolving deltas: 100% (120/120), done.\n",
            "Checking out files: 100% (52/52), done.\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "3AtCTvKVfzc8",
        "outputId": "be526ce1-cc49-4be3-9c17-2c8dee00d95e"
      },
      "source": [
        "cd MTLVS/"
      ],
      "execution_count": 14,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "/content/MTLVS\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "oNss0ZH6GhXh",
        "outputId": "3c4b60ee-e1d4-4332-f8b1-53fb36fd24ed"
      },
      "source": [
        "cd Codes/"
      ],
      "execution_count": 15,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "/content/MTLVS/Codes\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "5IT5lFiaiNt4",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "7111e190-7cba-4abd-f1b2-669db2e38103"
      },
      "source": [
        "%%time\n",
        "!python mtlvs.py"
      ],
      "execution_count": 23,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "2021-06-07 16:13:24.764797: I tensorflow/stream_executor/platform/default/dso_loader.cc:53] Successfully opened dynamic library libcudart.so.11.0\n",
            "GPU_ID = 0\n",
            "\n",
            "MODEL_NAME = BERTWEET\n",
            "IN_FEATURES = 768\n",
            "OUT_FEATURES = 128\n",
            "MODEL_SAVING_POLICY = loss\n",
            "VERI_LOSS_FN = nw\n",
            "SUMM_LOSS_FN = w\n",
            "LAMBDA = 0.7\n",
            "DELTA = 0.01\n",
            "FLOOD = n\n",
            "OPTIM = adam\n",
            "L2_REGULARIZER = y\n",
            "WEIGHT_DECAY = 0.01\n",
            "USE_DROPOUT = n\n",
            "NUM_ITERATIONS = 10\n",
            "BATCH_SIZE = 16\n",
            "LEARNING_RATES = [1e-06, 2e-06, 5e-06, 1e-05]\n",
            "TRAINABLE_LAYERS = [0, 1, 2, 3, 4, 5, 6, 7, 8, 9, 10, 11]\n",
            "\n",
            "TEST_FILE = german\n",
            "\n",
            "SEED = 1955\n",
            "\n",
            "\n",
            "There are 1 GPU(s) available.\n",
            "We will use the GPU: Tesla T4\n",
            "charliehebdo.txt Training Set Size: 1872, Validation Set Size: 207, Total: 2079\n",
            "germanwings-crash.txt Training Set Size: 423, Validation Set Size: 46, Total: 469\n",
            "ottawashooting.txt Training Set Size: 801, Validation Set Size: 89, Total: 890\n",
            "sydneysiege.txt Training Set Size: 1099, Validation Set Size: 122, Total: 1221\n",
            "Test file: charliehebdo.txt\n",
            "Statistics of training corpus:\n",
            "Total non-rumors: 1221, Total rumors: 1102\n",
            "Total non-summary-tweets: 2051, Total summary-tweets: 272\n",
            "Verification Class Weight Vector: tensor([0.9513, 1.0540], device='cuda:0', dtype=torch.float64)\n",
            "Verification Positive Class Weight Vector: tensor([1.1080], device='cuda:0')\n",
            "Summary Class Weight Vector: tensor([0.5663, 4.2702], device='cuda:0', dtype=torch.float64)\n",
            "Summary Positive Class Weight Vector: tensor([7.5404], device='cuda:0')\n",
            "Test file: germanwings-crash.txt\n",
            "Statistics of training corpus:\n",
            "Total non-rumors: 2466, Total rumors: 1306\n",
            "Total non-summary-tweets: 3334, Total summary-tweets: 438\n",
            "Verification Class Weight Vector: tensor([0.7648, 1.4441], device='cuda:0', dtype=torch.float64)\n",
            "Verification Positive Class Weight Vector: tensor([1.8882], device='cuda:0')\n",
            "Summary Class Weight Vector: tensor([0.5657, 4.3059], device='cuda:0', dtype=torch.float64)\n",
            "Summary Positive Class Weight Vector: tensor([7.6119], device='cuda:0')\n",
            "Test file: ottawashooting.txt\n",
            "Statistics of training corpus:\n",
            "Total non-rumors: 2305, Total rumors: 1089\n",
            "Total non-summary-tweets: 3000, Total summary-tweets: 394\n",
            "Verification Class Weight Vector: tensor([0.7362, 1.5583], device='cuda:0', dtype=torch.float64)\n",
            "Verification Positive Class Weight Vector: tensor([2.1166], device='cuda:0')\n",
            "Summary Class Weight Vector: tensor([0.5657, 4.3071], device='cuda:0', dtype=torch.float64)\n",
            "Summary Positive Class Weight Vector: tensor([7.6142], device='cuda:0')\n",
            "Test file: sydneysiege.txt\n",
            "Statistics of training corpus:\n",
            "Total non-rumors: 2048, Total rumors: 1048\n",
            "Total non-summary-tweets: 2760, Total summary-tweets: 336\n",
            "Verification Class Weight Vector: tensor([0.7559, 1.4771], device='cuda:0', dtype=torch.float64)\n",
            "Verification Positive Class Weight Vector: tensor([1.9542], device='cuda:0')\n",
            "Summary Class Weight Vector: tensor([0.5609, 4.6071], device='cuda:0', dtype=torch.float64)\n",
            "Summary Positive Class Weight Vector: tensor([8.2143], device='cuda:0')\n",
            "\n",
            "\n",
            "\n",
            "Training with LR:  1e-06\n",
            "model intialising...\n",
            "model intialising...\n",
            "L2_REGULARIZER = y and WEIGHT_DECAY = 0.01\n",
            "Training Set: {'ottawashooting.txt', 'sydneysiege.txt', 'charliehebdo.txt'}\n",
            "size of training data 3772\n",
            "Size of test data 469\n",
            "\n",
            "training started....\n",
            "train verifier\n",
            "train summarizer\n",
            "/usr/local/lib/python3.7/dist-packages/torch/nn/functional.py:1698: UserWarning: nn.functional.tanh is deprecated. Use torch.tanh instead.\n",
            "  warnings.warn(\"nn.functional.tanh is deprecated. Use torch.tanh instead.\")\n",
            "/usr/local/lib/python3.7/dist-packages/torch/nn/functional.py:1709: UserWarning: nn.functional.sigmoid is deprecated. Use torch.sigmoid instead.\n",
            "  warnings.warn(\"nn.functional.sigmoid is deprecated. Use torch.sigmoid instead.\")\n",
            "mtl_summar.py:837: UserWarning: torch.nn.utils.clip_grad_norm is now deprecated in favor of torch.nn.utils.clip_grad_norm_.\n",
            "  clip_grad_norm(net.parameters(), args.max_norm)\n",
            "validation started.. 418\n",
            "\n",
            "Iteration  0\n",
            "Verifier Training Loss:  tensor(0.6950, device='cuda:0', grad_fn=<DivBackward0>)\n",
            "Verification Training accuracy:  0.4375\n",
            "Validation loss:  tensor(0.6898, device='cuda:0')\n",
            "Verification Validation accuracy:  0.6028708133971292\n",
            "Verification Validation f1 score:  0.5241661180601271\n",
            "Validation accuracy of the model is  0.6028708133971292\n",
            "Validation loss of the model is  tensor(0.6898, device='cuda:0')\n",
            "Now Testing: germanwings-crash.txt\n",
            "Speed: 4.54 docs / s\n",
            "\n",
            "Total Test trees evaluated: 469\n",
            "Accuracy: 0.569296\n",
            "Precision: 0.565217\n",
            "Macro Precision: 0.570173\n",
            "Recall: 0.655462\n",
            "Macro Recall: 0.567991\n",
            "Micro F1 score: 0.607004\n",
            "Macro F1 score: 0.565294\n",
            "\n",
            "\n",
            "\n",
            "              precision    recall  f1-score   support\n",
            "\n",
            "           0    0.57513   0.48052   0.52358       231\n",
            "           1    0.56522   0.65546   0.60700       238\n",
            "\n",
            "    accuracy                        0.56930       469\n",
            "   macro avg    0.57017   0.56799   0.56529       469\n",
            "weighted avg    0.57010   0.56930   0.56592       469\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "confusion matrix  [[111 120]\n",
            " [ 82 156]]\n",
            "For alpha=0\n",
            "\n",
            "Summary generated for: german\n",
            "Total tweets: 16\n",
            "Total verified: 10\n",
            "Total later verified: 4\n",
            "Summary length with normalized tweets: 264\n",
            "Summary length with original tweets: 262\n",
            "Summary length with clean tweets: 245\n",
            "Verified_Ratio of tweets: 0.625\n",
            "Modified verified_Ratio of tweets: 0.875\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "Metric for:  Original_summary\n",
            "Evaluation with Avg\n",
            "\trouge-1:\tP: 57.96\tR: 52.73\tF1: 55.22\n",
            "\trouge-2:\tP: 32.53\tR: 29.59\tF1: 30.99\n",
            "\trouge-l:\tP: 61.00\tR: 56.38\tF1: 58.60\n",
            "\trouge-w:\tP: 31.46\tR: 15.62\tF1: 20.88\n",
            "\n",
            "Evaluation with Best\n",
            "\trouge-1:\tP: 57.96\tR: 52.73\tF1: 55.22\n",
            "\trouge-2:\tP: 32.53\tR: 29.59\tF1: 30.99\n",
            "\trouge-l:\tP: 61.00\tR: 56.38\tF1: 58.60\n",
            "\trouge-w:\tP: 31.46\tR: 15.62\tF1: 20.88\n",
            "\n",
            "Evaluation with Individual\n",
            "\tHypothesis #0 & Reference #0: \n",
            "\t\trouge-1:\tP: 57.96\tR: 52.73\tF1: 55.22\n",
            "\n",
            "\tHypothesis #0 & Reference #0: \n",
            "\t\trouge-2:\tP: 32.53\tR: 29.59\tF1: 30.99\n",
            "\n",
            "\tHypothesis #0 & Reference #0: \n",
            "\t\trouge-l:\tP: 61.00\tR: 56.38\tF1: 58.60\n",
            "\n",
            "\tHypothesis #0 & Reference #0: \n",
            "\t\trouge-w:\tP: 31.46\tR: 15.62\tF1: 20.88\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "Metric for:  Cleaned_summary\n",
            "Evaluation with Avg\n",
            "\trouge-1:\tP: 50.61\tR: 44.29\tF1: 47.24\n",
            "\trouge-2:\tP: 21.31\tR: 18.64\tF1: 19.89\n",
            "\trouge-l:\tP: 54.40\tR: 48.67\tF1: 51.38\n",
            "\trouge-w:\tP: 20.57\tR: 10.33\tF1: 13.75\n",
            "\n",
            "Evaluation with Best\n",
            "\trouge-1:\tP: 50.61\tR: 44.29\tF1: 47.24\n",
            "\trouge-2:\tP: 21.31\tR: 18.64\tF1: 19.89\n",
            "\trouge-l:\tP: 54.40\tR: 48.67\tF1: 51.38\n",
            "\trouge-w:\tP: 20.57\tR: 10.33\tF1: 13.75\n",
            "\n",
            "Evaluation with Individual\n",
            "\tHypothesis #0 & Reference #0: \n",
            "\t\trouge-1:\tP: 50.61\tR: 44.29\tF1: 47.24\n",
            "\n",
            "\tHypothesis #0 & Reference #0: \n",
            "\t\trouge-2:\tP: 21.31\tR: 18.64\tF1: 19.89\n",
            "\n",
            "\tHypothesis #0 & Reference #0: \n",
            "\t\trouge-l:\tP: 54.40\tR: 48.67\tF1: 51.38\n",
            "\n",
            "\tHypothesis #0 & Reference #0: \n",
            "\t\trouge-w:\tP: 20.57\tR: 10.33\tF1: 13.75\n",
            "\n",
            "\n",
            "For alpha=0.5\n",
            "\n",
            "Summary generated for: german\n",
            "Total tweets: 17\n",
            "Total verified: 3\n",
            "Total later verified: 8\n",
            "Summary length with normalized tweets: 254\n",
            "Summary length with original tweets: 246\n",
            "Summary length with clean tweets: 230\n",
            "Verified_Ratio of tweets: 0.17647058823529413\n",
            "Modified verified_Ratio of tweets: 0.6470588235294118\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "Metric for:  Original_summary\n",
            "Evaluation with Avg\n",
            "\trouge-1:\tP: 41.93\tR: 36.89\tF1: 39.24\n",
            "\trouge-2:\tP: 17.76\tR: 15.62\tF1: 16.62\n",
            "\trouge-l:\tP: 47.86\tR: 43.02\tF1: 45.31\n",
            "\trouge-w:\tP: 21.71\tR: 10.43\tF1: 14.09\n",
            "\n",
            "Evaluation with Best\n",
            "\trouge-1:\tP: 41.93\tR: 36.89\tF1: 39.24\n",
            "\trouge-2:\tP: 17.76\tR: 15.62\tF1: 16.62\n",
            "\trouge-l:\tP: 47.86\tR: 43.02\tF1: 45.31\n",
            "\trouge-w:\tP: 21.71\tR: 10.43\tF1: 14.09\n",
            "\n",
            "Evaluation with Individual\n",
            "\tHypothesis #0 & Reference #0: \n",
            "\t\trouge-1:\tP: 41.93\tR: 36.89\tF1: 39.24\n",
            "\n",
            "\tHypothesis #0 & Reference #0: \n",
            "\t\trouge-2:\tP: 17.76\tR: 15.62\tF1: 16.62\n",
            "\n",
            "\tHypothesis #0 & Reference #0: \n",
            "\t\trouge-l:\tP: 47.86\tR: 43.02\tF1: 45.31\n",
            "\n",
            "\tHypothesis #0 & Reference #0: \n",
            "\t\trouge-w:\tP: 21.71\tR: 10.43\tF1: 14.09\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "Metric for:  Cleaned_summary\n",
            "Evaluation with Avg\n",
            "\trouge-1:\tP: 31.74\tR: 26.07\tF1: 28.63\n",
            "\trouge-2:\tP:  5.24\tR:  4.30\tF1:  4.72\n",
            "\trouge-l:\tP: 37.55\tR: 31.87\tF1: 34.48\n",
            "\trouge-w:\tP: 14.85\tR:  7.00\tF1:  9.51\n",
            "\n",
            "Evaluation with Best\n",
            "\trouge-1:\tP: 31.74\tR: 26.07\tF1: 28.63\n",
            "\trouge-2:\tP:  5.24\tR:  4.30\tF1:  4.72\n",
            "\trouge-l:\tP: 37.55\tR: 31.87\tF1: 34.48\n",
            "\trouge-w:\tP: 14.85\tR:  7.00\tF1:  9.51\n",
            "\n",
            "Evaluation with Individual\n",
            "\tHypothesis #0 & Reference #0: \n",
            "\t\trouge-1:\tP: 31.74\tR: 26.07\tF1: 28.63\n",
            "\n",
            "\tHypothesis #0 & Reference #0: \n",
            "\t\trouge-2:\tP:  5.24\tR:  4.30\tF1:  4.72\n",
            "\n",
            "\tHypothesis #0 & Reference #0: \n",
            "\t\trouge-l:\tP: 37.55\tR: 31.87\tF1: 34.48\n",
            "\n",
            "\tHypothesis #0 & Reference #0: \n",
            "\t\trouge-w:\tP: 14.85\tR:  7.00\tF1:  9.51\n",
            "\n",
            "\n",
            "For alpha=1\n",
            "\n",
            "Summary generated for: german\n",
            "Total tweets: 19\n",
            "Total verified: 1\n",
            "Total later verified: 10\n",
            "Summary length with normalized tweets: 263\n",
            "Summary length with original tweets: 255\n",
            "Summary length with clean tweets: 239\n",
            "Verified_Ratio of tweets: 0.05263157894736842\n",
            "Modified verified_Ratio of tweets: 0.5789473684210527\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "Metric for:  Original_summary\n",
            "Evaluation with Avg\n",
            "\trouge-1:\tP: 36.31\tR: 34.43\tF1: 35.34\n",
            "\trouge-2:\tP: 15.90\tR: 15.07\tF1: 15.47\n",
            "\trouge-l:\tP: 42.42\tR: 40.58\tF1: 41.48\n",
            "\trouge-w:\tP: 18.85\tR:  9.75\tF1: 12.85\n",
            "\n",
            "Evaluation with Best\n",
            "\trouge-1:\tP: 36.31\tR: 34.43\tF1: 35.34\n",
            "\trouge-2:\tP: 15.90\tR: 15.07\tF1: 15.47\n",
            "\trouge-l:\tP: 42.42\tR: 40.58\tF1: 41.48\n",
            "\trouge-w:\tP: 18.85\tR:  9.75\tF1: 12.85\n",
            "\n",
            "Evaluation with Individual\n",
            "\tHypothesis #0 & Reference #0: \n",
            "\t\trouge-1:\tP: 36.31\tR: 34.43\tF1: 35.34\n",
            "\n",
            "\tHypothesis #0 & Reference #0: \n",
            "\t\trouge-2:\tP: 15.90\tR: 15.07\tF1: 15.47\n",
            "\n",
            "\tHypothesis #0 & Reference #0: \n",
            "\t\trouge-l:\tP: 42.42\tR: 40.58\tF1: 41.48\n",
            "\n",
            "\tHypothesis #0 & Reference #0: \n",
            "\t\trouge-w:\tP: 18.85\tR:  9.75\tF1: 12.85\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "Metric for:  Cleaned_summary\n",
            "Evaluation with Avg\n",
            "\trouge-1:\tP: 26.78\tR: 22.86\tF1: 24.66\n",
            "\trouge-2:\tP:  3.78\tR:  3.23\tF1:  3.48\n",
            "\trouge-l:\tP: 32.48\tR: 28.47\tF1: 30.34\n",
            "\trouge-w:\tP: 13.02\tR:  6.38\tF1:  8.56\n",
            "\n",
            "Evaluation with Best\n",
            "\trouge-1:\tP: 26.78\tR: 22.86\tF1: 24.66\n",
            "\trouge-2:\tP:  3.78\tR:  3.23\tF1:  3.48\n",
            "\trouge-l:\tP: 32.48\tR: 28.47\tF1: 30.34\n",
            "\trouge-w:\tP: 13.02\tR:  6.38\tF1:  8.56\n",
            "\n",
            "Evaluation with Individual\n",
            "\tHypothesis #0 & Reference #0: \n",
            "\t\trouge-1:\tP: 26.78\tR: 22.86\tF1: 24.66\n",
            "\n",
            "\tHypothesis #0 & Reference #0: \n",
            "\t\trouge-2:\tP:  3.78\tR:  3.23\tF1:  3.48\n",
            "\n",
            "\tHypothesis #0 & Reference #0: \n",
            "\t\trouge-l:\tP: 32.48\tR: 28.47\tF1: 30.34\n",
            "\n",
            "\tHypothesis #0 & Reference #0: \n",
            "\t\trouge-w:\tP: 13.02\tR:  6.38\tF1:  8.56\n",
            "\n",
            "\n",
            "train verifier\n",
            "train summarizer\n",
            "/usr/local/lib/python3.7/dist-packages/torch/nn/functional.py:1698: UserWarning: nn.functional.tanh is deprecated. Use torch.tanh instead.\n",
            "  warnings.warn(\"nn.functional.tanh is deprecated. Use torch.tanh instead.\")\n",
            "/usr/local/lib/python3.7/dist-packages/torch/nn/functional.py:1709: UserWarning: nn.functional.sigmoid is deprecated. Use torch.sigmoid instead.\n",
            "  warnings.warn(\"nn.functional.sigmoid is deprecated. Use torch.sigmoid instead.\")\n",
            "mtl_summar.py:837: UserWarning: torch.nn.utils.clip_grad_norm is now deprecated in favor of torch.nn.utils.clip_grad_norm_.\n",
            "  clip_grad_norm(net.parameters(), args.max_norm)\n",
            "validation started.. 418\n",
            "Traceback (most recent call last):\n",
            "  File \"/usr/local/lib/python3.7/dist-packages/torch/serialization.py\", line 372, in save\n",
            "    _save(obj, opened_zipfile, pickle_module, pickle_protocol)\n",
            "  File \"/usr/local/lib/python3.7/dist-packages/torch/serialization.py\", line 491, in _save\n",
            "    zip_file.write_record(name, storage.data_ptr(), num_bytes)\n",
            "KeyboardInterrupt\n",
            "\n",
            "During handling of the above exception, another exception occurred:\n",
            "\n",
            "Traceback (most recent call last):\n",
            "  File \"mtl_summar.py\", line 1375, in <module>\n",
            "    save_model(model, name, veri_val_acc, val_avg_loss)\n",
            "  File \"mtl_summar.py\", line 931, in save_model\n",
            "    torch.save(state, name)\n",
            "  File \"/usr/local/lib/python3.7/dist-packages/torch/serialization.py\", line 373, in save\n",
            "    return\n",
            "  File \"/usr/local/lib/python3.7/dist-packages/torch/serialization.py\", line 259, in __exit__\n",
            "    self.file_like.write_end_of_file()\n",
            "RuntimeError: [enforce fail at inline_container.cc:274] . unexpected pos 653222656 vs 653222544\n",
            "terminate called after throwing an instance of 'c10::Error'\n",
            "  what():  [enforce fail at inline_container.cc:274] . unexpected pos 653222656 vs 653222544\n",
            "frame #0: c10::ThrowEnforceNotMet(char const*, int, char const*, std::string const&, void const*) + 0x47 (0x7f0c128110e7 in /usr/local/lib/python3.7/dist-packages/torch/lib/libc10.so)\n",
            "frame #1: <unknown function> + 0x20699b0 (0x7f0c5080a9b0 in /usr/local/lib/python3.7/dist-packages/torch/lib/libtorch_cpu.so)\n",
            "frame #2: <unknown function> + 0x2065b83 (0x7f0c50806b83 in /usr/local/lib/python3.7/dist-packages/torch/lib/libtorch_cpu.so)\n",
            "frame #3: caffe2::serialize::PyTorchStreamWriter::writeRecord(std::string const&, void const*, unsigned long, bool) + 0xa9 (0x7f0c5080b329 in /usr/local/lib/python3.7/dist-packages/torch/lib/libtorch_cpu.so)\n",
            "frame #4: caffe2::serialize::PyTorchStreamWriter::writeEndOfFile() + 0xe1 (0x7f0c5080be61 in /usr/local/lib/python3.7/dist-packages/torch/lib/libtorch_cpu.so)\n",
            "frame #5: caffe2::serialize::PyTorchStreamWriter::~PyTorchStreamWriter() + 0x115 (0x7f0c5080c655 in /usr/local/lib/python3.7/dist-packages/torch/lib/libtorch_cpu.so)\n",
            "frame #6: <unknown function> + 0x7414a3 (0x7f0c614194a3 in /usr/local/lib/python3.7/dist-packages/torch/lib/libtorch_python.so)\n",
            "frame #7: <unknown function> + 0x36a1d8 (0x7f0c610421d8 in /usr/local/lib/python3.7/dist-packages/torch/lib/libtorch_python.so)\n",
            "frame #8: <unknown function> + 0x36b4de (0x7f0c610434de in /usr/local/lib/python3.7/dist-packages/torch/lib/libtorch_python.so)\n",
            "<omitting python frames>\n",
            "frame #19: __libc_start_main + 0xe7 (0x7f0c7a3c0bf7 in /lib/x86_64-linux-gnu/libc.so.6)\n",
            "\n",
            "CPU times: user 1.09 s, sys: 156 ms, total: 1.25 s\n",
            "Wall time: 3min 15s\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "dyP5c4xmKo2Q"
      },
      "source": [],
      "execution_count": null,
      "outputs": []
    }
  ]
}
